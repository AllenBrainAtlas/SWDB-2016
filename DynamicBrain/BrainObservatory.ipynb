{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../PythonBootcamp/support_files/cropped-SummerWorkshop_Header.png\">  \n",
    "\n",
    "<h1 align=\"center\">Introduction to the Allen Brain Observatory</h1> \n",
    "<h3 align=\"center\">August 24, 2016</h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>This notebook documents some classes and functions in the AllenSDK that help manipulate files and data structures in the Allen Brain Observatory. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# please make sure your drive_path is set, so that the notebook can find the data files on the hard drive\n",
    "\n",
    "# OS X\n",
    "drive_path = '/Volumes/Brain2016'\n",
    "\n",
    "# Windows (a good guess)\n",
    "# drive_path = 'e:/'\n",
    "\n",
    "# Linux (will vary; the following is possibly what Ubuntu will do)\n",
    "# drive_path = '/media/Brain2016/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We need to import these modules to get started\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>The main entry point is the `BrainObservatoryCache` class.  This class is responsible for downloading any requested data or metadata as needed and storing it in well known locations.  For this workshop, all of the data has been preloaded onto the hard drives you have received.\n",
    "\n",
    "<p>We begin by importing the `BrainObservatoryCache` class and instantiating it.\n",
    "\n",
    "<p>`manifest_path` is a path to the manifest file.  We will use the manifest file preloaded onto your Workshop hard drives.  Make sure that `drive_path` is set correctly for your platform.  (See the first cell in this notebook.)\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from allensdk.core.brain_observatory_cache import BrainObservatoryCache\n",
    "\n",
    "manifest_path = os.path.join(drive_path,'BrainObservatory','manifest.json')\n",
    "boc = BrainObservatoryCache(manifest_file=manifest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 1.1:**  Get information about what's in the dataset from BrainObservatoryCache\n",
    "\n",
    "<p>The following methods for BrainObservatoryCache retrieve the available depths, cre lines, areas, and stimuli.  Notice that these parameters outline the 'data cube'.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all targeted structures: [u'VISal', u'VISl', u'VISp', u'VISpm']\n",
      "all imaging depths: [175, 275, 350, 375]\n",
      "all cre lines: [u'Cux2-CreERT2', u'Rbp4-Cre', u'Rorb-IRES2-Cre', u'Scnn1a-Tg3-Cre']\n",
      "all stimuli: ['drifting_gratings', 'locally_sparse_noise', 'natural_movie_one', 'natural_movie_three', 'natural_movie_two', 'natural_scenes', 'spontaneous', 'static_gratings']\n"
     ]
    }
   ],
   "source": [
    "# Download a list of all targeted areas\n",
    "targeted_structures = boc.get_all_targeted_structures()\n",
    "print 'all targeted structures: ' + str(targeted_structures)\n",
    "\n",
    "# Download a list of all imaging depths\n",
    "depths = boc.get_all_imaging_depths()\n",
    "print 'all imaging depths: ' + str(depths)\n",
    "\n",
    "# Download a list of all cre driver lines \n",
    "cre_lines = boc.get_all_cre_lines()\n",
    "print 'all cre lines: ' + str(cre_lines)\n",
    "\n",
    "# Download a list of all stimuli\n",
    "stims = boc.get_all_stimuli()\n",
    "print 'all stimuli: ' + str(stims)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 1.2:**  Use tab completion in Jupyter to see what other methods the BrainObservatoryCache has.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hit the 'tab' key with the cursor just after the '.'\n",
    "boc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Experiment containers</h2>\n",
    "<p>The experiment container describes a set of 3 experiment sessions performed at the same location (targeted area and imaging depth) in the same mouse that targets the same set of cells. Each experiment container has a unique ID number.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 79 experiment containers.\n"
     ]
    }
   ],
   "source": [
    "expt_cont_list = boc.get_experiment_containers()\n",
    "\n",
    "print \"There are \" + str(len(expt_cont_list)) + \" experiment containers.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# example experiment_container_ids to use in this notebook\n",
    "expt_list = [511510699, 511510664, 511510797, 511507650, 511510917, \n",
    "             511510675, 511510911, 511510860, 511510658, 511498500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 1.3:** Pick an experiment container.  For this session we're going to need to get an experiment, which you'll use for the remainder of the tutorial.  Execute the following cells to do this.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOU GET AN EXPERIMENT CONTAINER!! EVERYONE GETS AN EXPERIMENT CONTAINER!!!\n",
      "expt_container_id = 511510699\n"
     ]
    }
   ],
   "source": [
    "# pick a random experiment container\n",
    "expt_index = np.random.randint(0,len(expt_list))\n",
    "# get expt_container_id for that index\n",
    "expt_container_id = expt_list[expt_index]\n",
    "\n",
    "print \"YOU GET AN EXPERIMENT CONTAINER!! EVERYONE GETS AN EXPERIMENT CONTAINER!!!\"\n",
    "print 'expt_container_id =',expt_container_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 1.3.1:** Find out the location and Cre line of this experiment container\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment container 511510695 is \n",
      "[{'targeted_structure': u'VISal', 'imaging_depth': 175, 'age_days': 143.0, 'id': 511510695, 'cre_line': u'Cux2-CreERT2'}]\n"
     ]
    }
   ],
   "source": [
    "print \"Experiment container \" + str(expt_container_id) + \" is \"\n",
    "print boc.get_experiment_containers(ids=[expt_container_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #FFF0F0; border-radius: 3px; padding: 10px;\">\n",
    "**Poll** Report your experiment container's targeted structure here:\n",
    "[Response](https://www.polleverywhere.com/multiple_choice_polls/xolRy5TQVGAhjdU)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 1.4:** Get information about all of the experiment <strong>sessions</strong> in your experiment <strong>container</strong>.  This is accomplished with the `get_ophys_experiments` method.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'session_type': u'three_session_B', 'age_days': 143.0, 'imaging_depth': 175, 'experiment_container_id': 511510695, 'targeted_structure': u'VISal', 'cre_line': u'Cux2-CreERT2', 'id': 503820068}, {'session_type': u'three_session_A', 'age_days': 143.0, 'imaging_depth': 175, 'experiment_container_id': 511510695, 'targeted_structure': u'VISal', 'cre_line': u'Cux2-CreERT2', 'id': 503412730}, {'session_type': u'three_session_C', 'age_days': 143.0, 'imaging_depth': 175, 'experiment_container_id': 511510695, 'targeted_structure': u'VISal', 'cre_line': u'Cux2-CreERT2', 'id': 504108263}]\n"
     ]
    }
   ],
   "source": [
    "expt_session_info = boc.get_ophys_experiments(experiment_container_ids=[expt_container_id])\n",
    "print(expt_session_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<p>`get_experiment_containers` returns a list of dictionaries that contain information about experiment containers.\n",
    "\n",
    "<p>`get_ophys_experiments` returns a list of dictionaries that contain information about experiment sessions.  Here we are using keyword arguments to return just those experiment sessions that belong to our experiment container.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 1.5:**  Turn it into a DataFrame for easy access\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_days</th>\n",
       "      <th>cre_line</th>\n",
       "      <th>experiment_container_id</th>\n",
       "      <th>id</th>\n",
       "      <th>imaging_depth</th>\n",
       "      <th>session_type</th>\n",
       "      <th>targeted_structure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143</td>\n",
       "      <td>Cux2-CreERT2</td>\n",
       "      <td>511510695</td>\n",
       "      <td>503820068</td>\n",
       "      <td>175</td>\n",
       "      <td>three_session_B</td>\n",
       "      <td>VISal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>143</td>\n",
       "      <td>Cux2-CreERT2</td>\n",
       "      <td>511510695</td>\n",
       "      <td>503412730</td>\n",
       "      <td>175</td>\n",
       "      <td>three_session_A</td>\n",
       "      <td>VISal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>143</td>\n",
       "      <td>Cux2-CreERT2</td>\n",
       "      <td>511510695</td>\n",
       "      <td>504108263</td>\n",
       "      <td>175</td>\n",
       "      <td>three_session_C</td>\n",
       "      <td>VISal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_days      cre_line  experiment_container_id         id  imaging_depth  \\\n",
       "0       143  Cux2-CreERT2                511510695  503820068            175   \n",
       "1       143  Cux2-CreERT2                511510695  503412730            175   \n",
       "2       143  Cux2-CreERT2                511510695  504108263            175   \n",
       "\n",
       "      session_type targeted_structure  \n",
       "0  three_session_B              VISal  \n",
       "1  three_session_A              VISal  \n",
       "2  three_session_C              VISal  "
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expt_session_frame = pd.DataFrame(expt_session_info)\n",
    "expt_session_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 1.1:**  Find all experiment sessions from a given area, depth, cre line, or specific stimulus. How many of each are there? (Hint:  use the `help` function to see the other optional arguments for `get_ophys_experiments` or `get_experiment_containers`.)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 1.2:**  Make a pandas table from all experiment sessions.  Perform Exercise 1.1 using this table.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 1.3:**  Find the experiment id for Session A from your experiment container.  Save this as `session_id`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Cell Specimens</h2>\n",
    "\n",
    "\n",
    "<p>`get_cell_specimens` is a method of the BrainObservatoryCache that provides important pre-computed characteristics of all the cells in the data set.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 1.5:**  Make a pandas table from the information returned by `get_cell_specimens` for just the cells in your experiment container. How many cells are in this container?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>cell_specimen_id</th>\n",
       "      <th>dsi_dg</th>\n",
       "      <th>experiment_container_id</th>\n",
       "      <th>imaging_depth</th>\n",
       "      <th>osi_dg</th>\n",
       "      <th>osi_sg</th>\n",
       "      <th>p_dg</th>\n",
       "      <th>p_ns</th>\n",
       "      <th>p_sg</th>\n",
       "      <th>...</th>\n",
       "      <th>pref_sf_sg</th>\n",
       "      <th>pref_tf_dg</th>\n",
       "      <th>time_to_peak_ns</th>\n",
       "      <th>time_to_peak_sg</th>\n",
       "      <th>tld1_id</th>\n",
       "      <th>tld1_name</th>\n",
       "      <th>tld2_id</th>\n",
       "      <th>tld2_name</th>\n",
       "      <th>tlr1_id</th>\n",
       "      <th>tlr1_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VISal</td>\n",
       "      <td>517503030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>511510695</td>\n",
       "      <td>175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.752529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.324820e-22</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.16585</td>\n",
       "      <td>0.36487</td>\n",
       "      <td>177839004</td>\n",
       "      <td>Cux2-CreERT2</td>\n",
       "      <td>177837320</td>\n",
       "      <td>Camk2a-tTA</td>\n",
       "      <td>265943423</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VISal</td>\n",
       "      <td>517503034</td>\n",
       "      <td>0.661227</td>\n",
       "      <td>511510695</td>\n",
       "      <td>175</td>\n",
       "      <td>0.733063</td>\n",
       "      <td>1.248231</td>\n",
       "      <td>0.340778</td>\n",
       "      <td>1.591583e-01</td>\n",
       "      <td>0.532933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4</td>\n",
       "      <td>0.33170</td>\n",
       "      <td>0.29853</td>\n",
       "      <td>177839004</td>\n",
       "      <td>Cux2-CreERT2</td>\n",
       "      <td>177837320</td>\n",
       "      <td>Camk2a-tTA</td>\n",
       "      <td>265943423</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VISal</td>\n",
       "      <td>517503039</td>\n",
       "      <td>2.573839</td>\n",
       "      <td>511510695</td>\n",
       "      <td>175</td>\n",
       "      <td>-4.138092</td>\n",
       "      <td>1.109775</td>\n",
       "      <td>0.555365</td>\n",
       "      <td>4.199616e-02</td>\n",
       "      <td>0.080133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2</td>\n",
       "      <td>0.29853</td>\n",
       "      <td>0.16585</td>\n",
       "      <td>177839004</td>\n",
       "      <td>Cux2-CreERT2</td>\n",
       "      <td>177837320</td>\n",
       "      <td>Camk2a-tTA</td>\n",
       "      <td>265943423</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VISal</td>\n",
       "      <td>517503044</td>\n",
       "      <td>2.698089</td>\n",
       "      <td>511510695</td>\n",
       "      <td>175</td>\n",
       "      <td>1.574695</td>\n",
       "      <td>1.769195</td>\n",
       "      <td>0.033663</td>\n",
       "      <td>1.894232e-01</td>\n",
       "      <td>0.379672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2</td>\n",
       "      <td>0.16585</td>\n",
       "      <td>0.23219</td>\n",
       "      <td>177839004</td>\n",
       "      <td>Cux2-CreERT2</td>\n",
       "      <td>177837320</td>\n",
       "      <td>Camk2a-tTA</td>\n",
       "      <td>265943423</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VISal</td>\n",
       "      <td>517503048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>511510695</td>\n",
       "      <td>175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>177839004</td>\n",
       "      <td>Cux2-CreERT2</td>\n",
       "      <td>177837320</td>\n",
       "      <td>Camk2a-tTA</td>\n",
       "      <td>265943423</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    area  cell_specimen_id    dsi_dg  experiment_container_id  imaging_depth  \\\n",
       "0  VISal         517503030       NaN                511510695            175   \n",
       "1  VISal         517503034  0.661227                511510695            175   \n",
       "2  VISal         517503039  2.573839                511510695            175   \n",
       "3  VISal         517503044  2.698089                511510695            175   \n",
       "4  VISal         517503048       NaN                511510695            175   \n",
       "\n",
       "     osi_dg    osi_sg      p_dg          p_ns      p_sg         ...          \\\n",
       "0       NaN  0.752529       NaN  4.324820e-22  0.000020         ...           \n",
       "1  0.733063  1.248231  0.340778  1.591583e-01  0.532933         ...           \n",
       "2 -4.138092  1.109775  0.555365  4.199616e-02  0.080133         ...           \n",
       "3  1.574695  1.769195  0.033663  1.894232e-01  0.379672         ...           \n",
       "4       NaN       NaN       NaN           NaN       NaN         ...           \n",
       "\n",
       "   pref_sf_sg  pref_tf_dg  time_to_peak_ns  time_to_peak_sg    tld1_id  \\\n",
       "0        0.02         NaN          0.16585          0.36487  177839004   \n",
       "1        0.08           4          0.33170          0.29853  177839004   \n",
       "2        0.02           2          0.29853          0.16585  177839004   \n",
       "3        0.02           2          0.16585          0.23219  177839004   \n",
       "4         NaN         NaN              NaN              NaN  177839004   \n",
       "\n",
       "      tld1_name    tld2_id   tld2_name    tlr1_id           tlr1_name  \n",
       "0  Cux2-CreERT2  177837320  Camk2a-tTA  265943423  Ai93(TITL-GCaMP6f)  \n",
       "1  Cux2-CreERT2  177837320  Camk2a-tTA  265943423  Ai93(TITL-GCaMP6f)  \n",
       "2  Cux2-CreERT2  177837320  Camk2a-tTA  265943423  Ai93(TITL-GCaMP6f)  \n",
       "3  Cux2-CreERT2  177837320  Camk2a-tTA  265943423  Ai93(TITL-GCaMP6f)  \n",
       "4  Cux2-CreERT2  177837320  Camk2a-tTA  265943423  Ai93(TITL-GCaMP6f)  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_specimens_df = pd.DataFrame(boc.get_cell_specimens(experiment_container_ids=[expt_container_id]))\n",
    "cell_specimens_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284\n"
     ]
    }
   ],
   "source": [
    "print len(cell_specimens_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #FFF0F0; border-radius: 3px; padding: 10px;\">\n",
    "**Poll** How many cells are in your experiment container? Answer here: [response](https://www.polleverywhere.com/free_text_polls/cXVrJnkXpPZA6ce)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 1.4:**  Filter the table from the previous task to find all cells in your experiment container id that have `dsi_dg` (Direction Selectivity Index for Drifting Gratings) < 1.0.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 1.5:**  Find the cell in your filtered dataframe that has the largest `dsi_dg` that is less than 1.0.  Save the cell_specimen_id of this cell to a variable called `cell_specimen_id`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 1.6:**  Find the preferred direction and temporal frequency for the cell you have identified in `cell_specimen_id`.  Save these to `ori` and `tf`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #FFF0F0; border-radius: 3px; padding: 10px;\">\n",
    "**Poll** What is the preferred temporal frequency of your cell? Respond [here](https://www.polleverywhere.com/multiple_choice_polls/cn8I6mSMithCcKI)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>We will be using the cell you have recorded in `cell_specimen_id` for much of the remainder of this notebook.\n",
    "\n",
    "<h2>The Data Object</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 2.1:**  Create a data_set object for this experiment session.\n",
    "\n",
    "The data_set object contains methods and info for a single experiment session (one of the 3 in the experiment container)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_set = boc.get_ophys_experiment_data(ophys_experiment_id = session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 2.2:** Use either `dir` or tab-completion to find out what methods the new `data_set` object has.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<p>Using the methods you find, perform the following exercises.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 2.1:** Get the metadata for your data set. How old was the mouse in this experiment?  Was it male or female?  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #FFF0F0; border-radius: 3px; padding: 10px;\">\n",
    "**Poll** What was the sex of the mouse in your experiment? Respond [here](https://www.polleverywhere.com/multiple_choice_polls/ZuaLuwbeWqAjTfl)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 2.3:** Get the max projection image for your data set.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 2.4:** Let's find the cell you recorded in `cell_specimen_id` in `data_set`.  `cell_specimen_id` is a unique cell identifier that is used across multiple sessions in which that cell appears.  For each individual session, each cell has an index specific to that session.  There are two methods of data_set that allow you to map back and forth between these two identifiers.  Find them and use one of them to save the session identifier for your cell to `cell_index`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 2.5:** Get the roi mask for your cell.  (Hint:  There are two methods that return roi masks.  In one of them masks are returned as lists of python objects.  What methods do they have?  What is the type of this object?)  What is the size and shape of the mask?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 2.6:** Plot the mask overlayed on the max projection.  (Hint:  imshow has an optional parameter called `alpha`.)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #FFF0F0; border-radius: 3px; padding: 10px;\">\n",
    "**Poll** Are you having [fun?](https://www.polleverywhere.com/multiple_choice_polls/8SUrezEJfhoK7FY)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 2.7:**  What kinds of traces can you extract from the data object?  Retrieve the \"corrected fluorescence\" traces.   What is the shape of this object?  The methods will return a tuple of length two.  The first value is the set of time stamps for the acquisition frames; the second is an array of shape (number_of_cells,time_points).  How many cells are in your data set?  Plot the \"corrected fluorescence\" trace for the cell you saved in `cell_session_id`. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stimuli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 3.1:**  What stimuli were shown in this session? Use a method of the data_set object to find out.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>The stimulus table stores the timing information regarding stimulus conditions\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 3.2:** Use a method of the data_set object to get the stimulus_table for drifting gratings.  (Use help to find the necessary arguments for the method.)  What kind of object is this?  How many stimulus conditions are there?  How many orientations?  How many temporal frequencies?  How many trials of each condition were shown?  How long was each presentation?  (Hint:  use boolean indexing.)\n",
    "\n",
    "<p><strong>Important hint</strong>: trial start and end times are in aquisition frames, which count each frame acquired by the two-photon microscope, not seconds.  This is the same index used for the fluorescence traces.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 3.3:**> Plot the fluorescence trace for the cell in `cell_session_id` for a few trials using the start, end times of the trials.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 3.4:** Create a plot that shows when the drifting gratings were displayed.  (Hint:  avxspan is an axis object method that will fill in the background between two x positions.  See the following example.)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.patches.Polygon at 0x11a2adc50>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEACAYAAACwB81wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a2ade10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(1)\n",
    "\n",
    "t = np.linspace(0,2.0*np.pi,1000)\n",
    "ax.plot(t,np.cos(t))\n",
    "ax.axvspan(xmin=np.pi/4,xmax=7*np.pi/4,color='g',alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Analysis</h2>\n",
    "\n",
    "\n",
    "<p>The analysis objects summarize this trial data and provide convenient DataFrame objects.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 3.1:**  Import the `DriftingGratings` object and instatiate it with `data_set`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from allensdk.brain_observatory.drifting_gratings import DriftingGratings\n",
    "\n",
    "dg = DriftingGratings(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<p>sweep_response is a DataFrame that contains the dF/F response of each cell during each stimulus trial. It shares its index with stim_table. Each cell contains a timeseries that extends from 1 second prior to the start of the trial to 1 second after the end of the trial. The sweep_response table is organized as cells (columns) for each sweep (rows)\n",
    "\n",
    "<p>mean_sweep_response provides the mean dF/F for each trial.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 3.5:** Get the sweep_response for this stimulus and data set.  What type of object is this?  What data does it contain?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 3.6:** Get the mean_sweep_response for this stimulus and data set.  How does this object differ from sweep_response?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 3.7:** Find the trials for a specific stimulus condition\n",
    "(ex: temporal_frequency = 2 and orientation = 90).  Use the stimulus table and boolean indexing.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 3.8:** Use the trials you've found and the sweep_response table to plot the response across trials.  (Extra credit for highlighting the interval over which the stimulus is 'on'.)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 3.9:**  Compute and plot the mean response over trials for the preferred condition for your selected cell.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 3.10:**  Repeat this process using `mean_sweep_response` in order to compute a single numerical value for the response to the preferred orientation and temporal frequency.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 3.11:**  Generate a matrix of response values over all direction and temporal frequency conditions by repeating the previous calculation for each condition.  Plot a heat map of the mean response across all stimulus conditions.  Plot direction and temporal frequency tuning curves by averaging over each.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 3.2:**  The easy way!  We did this as a pedagogic exercise so that you could learn about the sdk and the data.  Should you need it, this matrix has been computed already and is available in the `response` attribute for `DriftingGratings`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Other Stimulus Types</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 3.2:**  There are analysis objects for the other stimulus types.  You saw above that Session A contains responses for drifting gratings, natural movies, and spontaneous activity.  Instantiate the Natural Movie object and see what methods and attributes are available.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from allensdk.brain_observatory.natural_movie import NaturalMovie \n",
    "\n",
    "nm1 = NaturalMovie(data_set)  #how to pick which movie, check sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 3.12:**  There are also objects for StaticGratings, NaturalScenes, and LocallySparseNoise.  For each of these, use what you've learned to find an experiment with each of these stimulus types, instantiate the analysis object, and explore the stimulus tables and available attributes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from allensdk.brain_observatory.static_gratings import StaticGratings\n",
    "from allensdk.brain_observatory.natural_scenes import NaturalScenes\n",
    "from allensdk.brain_observatory.locally_sparse_noise import LocallySparseNoise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 3.13:**  Load the stimulus template for the LocallySparseNoise stimulus. Plot the first frame of the stimulus.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session_id_C = expt_session_frame[expt_session_frame.session_type=='three_session_C'].id.values[0]\n",
    "data_set_C = boc.get_ophys_experiment_data(ophys_experiment_id = session_id_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsn_template = data_set_C.get_stimulus_template('locally_sparse_noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 3.14:**  Find all of the frames with a white square located at x=0,y=0. How many frames are there?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Exercises or Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Homework 1:**  Compute Receptive Fields for the ON and OFF responses using the Locally Sparse Noise stimulus.  (If you're having trouble, try testing your code on this cell_specimen_id:   )\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Homework 2:**  Pick an image from the Natural Scenes. Find all of the cells from which this is the preferred image. Determine the spatial frequency tuning of those cells. Does it differ from the population as a whole? Does it differ across areas, Cre lines, layers?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Project Ideas</h2>\n",
    "\n",
    "<p>Here are some ideas to get you started in thinking about your projects.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "<li> How do cells' responses differ across regions, layers, and Cre lines?  How best can these differences be captured?\n",
    "<li> What is the distribution of feature responses?  How does preferred orientation, say, vary across regions, layers, and Cre lines?\n",
    "<li> Do the responses to one type of stimulus allow us to predict the responses to a different type?  Are grating responses consistent with natural image responses?\n",
    "<li> Can you distinguish \"simple\" and \"complex\" cells in the dataset?  What is the right model or metric to use?\n",
    "<li> Characterize the cross correlations (both \"noise\" and \"signal\" correlations) in the data set.  Can you model this variability?  \n",
    "<li> Develop models of stimulus response that control for running speed or include temporal dynamics.\n",
    "<li> How well can you identify the stimulus category given the activity of a set of neurons within an experiment, i.e. can you \"decode\" the stimulus?  What is the best way to do this?  What features are necessary?  Can you identify cells that carry \"more\" information about stimuli?\n",
    "<li> What population metrics are useful for describing the data?  Can you model the population activity?\n",
    "<li> What is the best way to visualize the activity of many cells in an experiment?  Is there a useful dimensional reduction that can help you?\n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
