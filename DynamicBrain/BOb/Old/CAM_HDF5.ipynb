{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to HDF5\n",
    "\n",
    "The Neurodata Without Borders (NWB) files you have been using for previous data sets and will be using for the CAM data set are actually HDF5 files.  HDF5 is a file format designed for handling large data sets.\n",
    "\n",
    "Since the raw data for CAM is given to you in this format, here is a brief introduction to extracting data from these files and creating and writing to your own HDF5 data files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##h5py\n",
    "\n",
    "The Python interface to HDF5 is given in the h5py module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "#some other things we'll use\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assuming you have one of the Summer Workshop on the Dynamic Brain disks, the data will be in these directories\n",
    "\n",
    "# path to CAM data\n",
    "cam_dir = '/Volumes/Brain2015/CAM/'\n",
    "\n",
    "# pick an experiment number\n",
    "expt = str(482591434)\n",
    "\n",
    "# The uncorrected raw data (for those experiments that have it) is labeled by expt_compressed.h5\n",
    "raw_data_path = os.path.join(cam_dir,expt,expt+'_compressed.h5')\n",
    "\n",
    "# The motion corrected data is labeled 'concat_31Hz_0_compressed.h5'\n",
    "motion_corrected_data_path = os.path.join(cam_dir,expt,'concat_31Hz_0_compressed.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating h5py objects\n",
    "\n",
    "You access data in HDF5 files via a File object, created as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "motion_corrected_data = h5py.File(motion_corrected_data_path,'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'r' here refers to the access mode (for read), you can also open files with modes \n",
    "\n",
    "r+ :  read and write\n",
    "\n",
    "w  :  write and create a new file (This will erase a previous file!)\n",
    "\n",
    "w- or x :  write and fail if the file exists\n",
    "\n",
    "a  :  'append', read/write if the file exists, create otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# h5py uses a dictionary interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "motion_corrected_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "motion_corrected_data['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various useful parameters of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print  \"Shape for 'data' is \",motion_corrected_data['data'].shape\n",
    "print  \"dtype for 'data' is \",motion_corrected_data['data'].dtype\n",
    "print  \"Compression type is \",motion_corrected_data['data'].compression\n",
    "print  \"compression_opts value is \",motion_corrected_data['data'].compression_opts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can slice just like numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print motion_corrected_data['data'][0,0:10,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(motion_corrected_data['data'][0],cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grabbing a region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(motion_corrected_data['data'][0,265:290,170:190],interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(motion_corrected_data['data'][0,240:270,225:255],interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time trace of a single pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(motion_corrected_data['data'][:,280,183])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use slicing to compute traces for regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trace = motion_corrected_data['data'][:,265:290,170:190].mean(axis=(1,2))\n",
    "\n",
    "plt.plot(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "another_trace = motion_corrected_data['data'][:,240:270,225:255].mean(axis=(1,2))\n",
    "\n",
    "plt.plot(another_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating new HDF5 files\n",
    "\n",
    "For reference, here is an example of creating hdf5 files and datasets.\n",
    "\n",
    "Use 'create_dataset' to add datasets to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a new h5py object in write mode 'w'  \n",
    "#THIS WILL DELETE ANY PREVIOUS FILE!!!\n",
    "new_data_path = os.path.join(cam_dir,'new_data.h5')\n",
    "new_data = h5py.File(new_data_path,'w')    \n",
    "\n",
    "new_data.create_dataset('trace',shape=trace.shape,dtype=trace.dtype)\n",
    "new_data['trace'][...]=trace\n",
    "\n",
    "#don't forget to close the file\n",
    "new_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a new h5py object in append mode 'a'\n",
    "new_data_path = os.path.join(cam_dir,'new_data.h5')\n",
    "new_data = h5py.File(new_data_path,'a')    \n",
    "\n",
    "new_data.create_dataset('another_trace',data=another_trace)   #shape=trace.shape,dtype=trace.dtype)\n",
    "new_data['another_trace'][...]= another_trace - np.mean(another_trace)\n",
    "\n",
    "new_data['trace'][:] = new_data['trace'].value - np.mean(new_data['trace'].value)\n",
    "\n",
    "#don't forget to close the file\n",
    "new_data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access our file and verify the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_data = h5py.File(new_data_path,'r')\n",
    "\n",
    "plt.plot(my_data['trace'])\n",
    "plt.plot(my_data['another_trace'])\n",
    "\n",
    "my_data.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
