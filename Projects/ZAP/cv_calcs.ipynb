{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drive_path = 'd:/'\n",
    "import glob\n",
    "#path = r'd:/BrainObservatory/ophys_analysis/'\n",
    "file_path = r'd:/BrainObservatory/ophys_analysis/*.h5'\n",
    "file_list = glob.glob(file_path)\n",
    "\n",
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from allensdk.core.brain_observatory_cache import BrainObservatoryCache\n",
    "manifest_path = os.path.join(drive_path,'BrainObservatory/manifest.json')\n",
    "boc = BrainObservatoryCache(manifest_file=manifest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this chunk of code is to compute the CV for the OS and DS during drifting gratings. Because there are only half of the directions, \n",
    "#I think it makes sense to use exp1j1 instead of exp 1j2. Try both ways see what happens\n",
    "#allPeakSFphs\n",
    "file_path = r'd:/BrainObservatory/ophys_analysis/*.h5'\n",
    "file_list = glob.glob(file_path)\n",
    "\n",
    "orivals_rad = np.deg2rad([0,45,90,135,180,225,270,315])\n",
    "cv_dgsMeanO=[]\n",
    "cv_dgsMeanD=[]\n",
    "cv_dgsMeanPO=[]\n",
    "cv_dgsMeanPD=[]\n",
    "drifting_csids=[]\n",
    "\n",
    "for file in file_list:\n",
    "    f = h5py.File(file)\n",
    "    exp_id = file[35:44]\n",
    "    if 'session_A' in file:\n",
    "        data_set = boc.get_ophys_experiment_data(int(exp_id))\n",
    "        csids = data_set.get_cell_specimen_ids()      \n",
    "        response = f[\"analysis/response_dg\"].value\n",
    "        f.close()\n",
    "        dg_means = response[:,1:,:-1,0]\n",
    "        peak = pd.read_hdf(file, 'analysis/peak')\n",
    "        TFpeak=(peak.tf_dg-1).values\n",
    "        for i in range(dg_means.shape[2]):\n",
    "            drifting_csids.append(csids[i])\n",
    "            peakTFs=dg_means[:,TFpeak[i],i]\n",
    "            meanTFs=np.ndarray.mean(dg_means[:,:,i],axis=1)\n",
    "            tuning = meanTFs[:]\n",
    "            tuning = np.where(tuning>0,tuning,0) #this is the fixed version that Saskia is computing now! don't forget 2theta for OS and 1 theta for DS\n",
    "            tuningp = peakTFs[:]\n",
    "            tuningp = np.where(tuningp>0,tuning,0)\n",
    "            CV_topO = np.empty((8),dtype=np.complex128)\n",
    "            CV_topD = np.empty((8),dtype=np.complex128)\n",
    "            CV_topPO = np.empty((8),dtype=np.complex128)\n",
    "            CV_topPD = np.empty((8),dtype=np.complex128)\n",
    "            for i in range(8):\n",
    "                CV_topO[i] = (tuning[i] * np.exp(1j * 2 * orivals_rad[i])).real\n",
    "                CV_topD[i] = (tuning[i] * np.exp(1j * orivals_rad[i])).real\n",
    "                CV_topPO[i] = (tuningp[i] * np.exp(1j * 2 * orivals_rad[i])).real\n",
    "                CV_topPD[i] = (tuningp[i] * np.exp(1j * orivals_rad[i])).real\n",
    "            cv_dgsMeanO.append(np.abs(CV_topO.sum() / tuning.sum()))\n",
    "            cv_dgsMeanD.append(np.abs(CV_topD.sum() / tuning.sum()))\n",
    "            cv_dgsMeanPO.append(np.abs(CV_topPO.sum() / tuningp.sum()))\n",
    "            cv_dgsMeanPD.append(np.abs(CV_topPD.sum() / tuningp.sum()))\n",
    "#             allcv_sgsO.append(cv_sgsO)\n",
    "#             allcv_sgsD.append(cv_sgsD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# file=r'D:\\BrainObservatory\\ophys_analysis\\497256116_three_session_B_analysis.h5'\n",
    "# f = h5py.File(file)\n",
    "# f['analysis'].keys()\n",
    "# #response = f[\"analysis/response_sg\"].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#same as above but for static\n",
    "file_path = r'd:/BrainObservatory/ophys_analysis/*.h5'\n",
    "#file_dir=r'd:/BrainObservatory/ophys_analysis/'\n",
    "file_list = glob.glob(file_path)\n",
    "#file_list=os.listdir(file_dir)\n",
    "\n",
    "cv_sgs_peaks=[]\n",
    "cv_sgs_pSF=[]\n",
    "cv_sgs_pPH=[]\n",
    "cv_sgs_means=[]\n",
    "orivals_rad = np.deg2rad([0,30,60,90,120,150])\n",
    "\n",
    "allcsids=[]\n",
    "a=[]\n",
    "for file in file_list:\n",
    "    f = h5py.File(file)\n",
    "    #f=h5py.File(os.path.join(file_dir,file))\n",
    "    exp_id = file[35:44]\n",
    "    if 'session_B' in file:\n",
    "        data_set = boc.get_ophys_experiment_data(int(exp_id))\n",
    "        csids = data_set.get_cell_specimen_ids()\n",
    "        response = f[\"analysis/response_sg\"].value\n",
    "        f.close()\n",
    "        sg_means = response[:,1:,:,:-1,0]\n",
    "        peak = pd.read_hdf(file, 'analysis/peak')\n",
    "        SFpeak=(peak.sf_sg-1).values\n",
    "        PHpeak=(peak.phase_sg).values\n",
    "        for i in range(sg_means.shape[3]):\n",
    "            allcsids.append(csids[i])\n",
    "            peakSFPHs=sg_means[:,SFpeak[i],PHpeak[i],i]\n",
    "            peakSFmPHs=np.ndarray.mean(sg_means[:,SFpeak[i],:,i],axis=1)\n",
    "            peakPHmSFs=np.ndarray.mean(sg_means[:,:,PHpeak[i],i],axis=1)\n",
    "            means=np.ndarray.mean(sg_means[:,:,:,i],axis=1)\n",
    "            means=np.ndarray.mean(means[:,:],axis=1)\n",
    "            #tuning = peaks[:]\n",
    "            peakSFPHs = np.where(peakSFPHs>0,peakSFPHs,0) #don't forget 2theta for OS and 1 theta for DS\n",
    "            peakSFmPHs = np.where(peakSFmPHs>0,peakSFmPHs,0)\n",
    "            peakPHmSFs = np.where(peakPHmSFs>0,peakPHmSFs,0)\n",
    "            means = np.where(means>0,means,0)\n",
    "            CV_top = np.empty((6),dtype=np.complex128)\n",
    "            CV_topSFmP = np.empty((6),dtype=np.complex128)\n",
    "            CV_topPmSF = np.empty((6),dtype=np.complex128)\n",
    "            CV_m = np.empty((6),dtype=np.complex128)\n",
    "            for i in range(6):\n",
    "                CV_top[i] = (peakSFPHs[i] * np.exp(1j * orivals_rad[i])).real\n",
    "                CV_topSFmP[i] = (peakSFmPHs[i] * np.exp(1j * orivals_rad[i])).real\n",
    "                CV_topPmSF[i] = (peakPHmSFs[i] * np.exp(1j * orivals_rad[i])).real\n",
    "                CV_m[i] = (means[i] * np.exp(1j * orivals_rad[i])).real\n",
    "            cv_sgs_peaks.append(np.abs(CV_top.sum() / peakSFPHs.sum()))\n",
    "            cv_sgs_pSF.append(np.abs(CV_topSFmP.sum() / peakSFmPHs.sum()))\n",
    "            cv_sgs_pPH.append(np.abs(CV_topPmSF.sum() / peakPHmSFs.sum()))\n",
    "            cv_sgs_means.append(np.abs(CV_m.sum() / means.sum()))\n",
    "            \n",
    "        #allcv_sgs.append(cv_sgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DG_data_dict = {\n",
    "    'cv_dgsMeanO':cv_dgsMeanO,\n",
    "    'cv_dgsMeanD':cv_dgsMeanD,\n",
    "    'cv_dgsPeakO':cv_dgsMeanPO,\n",
    "    'cv_dgsPeakD':cv_dgsMeanPD,\n",
    "    'drifting_csids':drifting_csids\n",
    "    }\n",
    "\n",
    "SG_data_dict = {\n",
    "    'cv_sgs_peaks':cv_sgs_peaks,\n",
    "    'cv_sgs_pSF':cv_sgs_pSF,\n",
    "    'cv_sgs_pPH':cv_sgs_pPH,\n",
    "    'cv_sgs_means':cv_sgs_means,\n",
    "    'static_csids':allcsids\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('SG_data_dict',SG_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('DG_data_dict',DG_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(DG_data_dict, open(\"DG_data_dict.p\",\"wb\"))\n",
    "pickle.dump(SG_data_dict, open(\"SG_data_dict.p\",\"wb\"))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
