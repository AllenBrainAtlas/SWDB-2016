{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append(\"/home/tom/python/dPCA/python\")\n",
    "sys.path.append(\"/Users/nick/Dropbox/dynamic_brain/dPCA/python\")\n",
    "from dPCA import dPCA\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.decomposition as deco\n",
    "import scipy.ndimage as img\n",
    "import os\n",
    "#import sys\n",
    "\n",
    "# import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#plt.style.use('ggplot')\n",
    "\n",
    "from allensdk.core.brain_observatory_cache import BrainObservatoryCache\n",
    "# from allensdk.brain_observatory.drifting_gratings import DriftingGratings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dataset and driftingGratings objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#manifest_path = os.path.join('/media/tom/Brain2016/','BrainObservatory','manifest.json')\n",
    "manifest_path = os.path.join('/Volumes/Brain2016/','BrainObservatory','manifest.json')\n",
    "boc = BrainObservatoryCache(manifest_file=manifest_path)\n",
    "select = False\n",
    "n_max = 10\n",
    "\n",
    "df_expts = pd.DataFrame(boc.get_experiment_containers())\n",
    "df_expts['fa'] = None\n",
    "df_expts['pca'] = None\n",
    "df_expts['dpca'] = None\n",
    "\n",
    "for i, expt_container_id in enumerate(df_expts['id']):\n",
    "    _, _, matAvg, ndAvg = extract_data_dg(boc, expt_container_id, selectcells=select)\n",
    "    n_components = min([n_max, matAvg.shape[1]])\n",
    "    result = pc_analysis(matAvg, n_components)\n",
    "    df_expts.at[i, 'pca'] = result['ev']\n",
    "    result = factor_analysis(matAvg, n_components)\n",
    "    df_expts.at[i, 'fa'] = result['ev']\n",
    "    result = dpc_analysis(ndAvg, matAvg, n_components)\n",
    "    df_expts.at[i, 'dpca'] = result['ev']\n",
    "    \n",
    "df_expts.to_json('results_dg_rand_1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_data_dg(boc, expt_container_id, selectcells=False):\n",
    "    cell_ids_example = None\n",
    "    \n",
    "    interlength = 30\n",
    "    sweeplength = 60\n",
    "    tlength = interlength + sweeplength\n",
    "    typeStim = 'drifting_gratings'\n",
    "    typeSession = 'three_session_A'\n",
    "    \n",
    "    expt_session_frame = pd.DataFrame(boc.get_ophys_experiments(experiment_container_ids=[expt_container_id]))\n",
    "    session_id = expt_session_frame[expt_session_frame.session_type==typeSession].id.values[0]  \n",
    "    data_set = boc.get_ophys_experiment_data(ophys_experiment_id = session_id)  \n",
    "    stim_table = data_set.get_stimulus_table(typeStim)\n",
    "    \n",
    "    if selectcells:\n",
    "        #path = '/media/Storage/Dropbox/dynamic_brain/chaoqing/subset_cells/exp-' + str(session_id) + '_cell_id_subset.dat'\n",
    "        path = 'subset_cells/exp-' + str(session_id) + '_cell_id_subset.dat'\n",
    "        good_cell = np.loadtxt(path)\n",
    "        cell_specimens_df = pd.DataFrame(boc.get_cell_specimens())\n",
    "        cell_ids_example = [cell for cell in good_cell if cell_specimens_df[cell_specimens_df.cell_specimen_id==cell].p_dg.values[0]<0.05]\n",
    "        index = np.argsort(data_set.get_cell_specimen_indices(cell_ids_example))\n",
    "        cell_ids_example = np.array(cell_ids_example)[index]\n",
    "        cell_ids_example = np.sort(np.random.choice(data_set.get_cell_specimen_indices(), len(cell_ids_example), replace=False))\n",
    "        \n",
    "\n",
    "    time, dff = data_set.get_dff_traces(cell_ids_example)\n",
    "    timetrial = time[range(tlength)]\n",
    "    N = dff.shape[0]\n",
    "    sweep_response = pd.DataFrame(index=stim_table.index.values, columns=np.arange(N).astype(str))\n",
    "    for i in range(stim_table.shape[0]):\n",
    "        for j in range(N):\n",
    "            sweep_response.at[i,str(j)] = 100*dff[\n",
    "                j, stim_table.at[i,'start'] + range(tlength)]\n",
    "\n",
    "\n",
    "    df_all = pd.concat([sweep_response, stim_table], axis=1)\n",
    "    matAll = np.column_stack([np.concatenate([df_all.iat[i,j] for i in range(df_all.shape[0])]) \n",
    "                           for j in range(N)])\n",
    "\n",
    "    all_mean = df_all.groupby(['orientation','temporal_frequency']).apply(lambda x: np.sum(x, axis=0)/len(x))\n",
    "    all_mean = all_mean[all_mean.temporal_frequency != 0] #cut static grating \n",
    "    all_mean['i'] = range(all_mean.shape[0])\n",
    "    matAvg = np.column_stack([np.concatenate([all_mean.iat[i,j] for i in range(all_mean.shape[0])]) \n",
    "                           for j in range(N)])\n",
    "\n",
    "    df_multi = all_mean.set_index(['orientation','temporal_frequency']) #cell, tf, ori, time\n",
    "    ndAvg = np.stack([np.stack([np.stack([df_multi.at[(i1,i2),str(j)] \n",
    "                                          for i1 in np.unique(df_multi.index.get_level_values(0))],0)\n",
    "                                for i2 in np.unique(df_multi.index.get_level_values(1))],0)\n",
    "                      for j in range(N)],0)\n",
    "\n",
    "    \n",
    "#     df_all.to_csv('data/'+str(expt_container_id)+'_df_all.csv')\n",
    "    return all_mean, matAll, matAvg, ndAvg\n",
    "\n",
    "def factor_analysis(mat, n_components):\n",
    "    mat = mat - mat.mean(axis=0, keepdims=True)\n",
    "    totVar = np.sum(np.square(mat))\n",
    "    expVar = np.zeros(n_components)\n",
    "    ll = np.zeros(n_components)\n",
    "    for ni in range(n_components):\n",
    "        dec = deco.FactorAnalysis(ni+1).fit(mat)\n",
    "        matReduced = dec.transform(mat)\n",
    "        matRcons = np.dot(matReduced,dec.components_)\n",
    "        expVar[ni] = 1 - np.sum(np.square(mat - matRcons))/totVar\n",
    "    return {'obj':dec, 'ev':expVar, 'trans':matReduced, 'enc':dec.components_}\n",
    "\n",
    "def pc_analysis(mat, n_components):\n",
    "    dec = deco.PCA(n_components, whiten=False).fit(mat)\n",
    "    ev = np.cumsum(dec.explained_variance_ratio_)\n",
    "    return {'obj':dec, 'ev':ev, 'trans':dec.transform(mat), 'enc':dec.components_}\n",
    "\n",
    "def dpc_analysis(mat, matAvg, ncomps):\n",
    "    combinedParams = {'f': ['f', 'ft'] , 'o': ['o', 'ot'], 'fo': ['fo', 'fot']}\n",
    "    dec = dPCA(labels='fot', n_components=ncomps, join=combinedParams).fit(mat)\n",
    "    V = np.hstack(dec.P.values())\n",
    "    W = np.hstack(dec.D.values())\n",
    "\n",
    "    # flipping axes such that all encoders have more positive values\n",
    "    toFlip = np.nonzero(np.sum(V, axis=0)<0)\n",
    "    W[:, toFlip] = -W[:, toFlip]\n",
    "    V[:, toFlip] = -V[:, toFlip]\n",
    "\n",
    "    X = ndAvg.reshape((ndAvg.shape[0],-1))\n",
    "    X -= np.mean(X, axis=1, keepdims=True)\n",
    "    totalVar = np.sum(np.square(X))\n",
    "\n",
    "    Z = np.dot(W.T,X)\n",
    "    explVar = [1 - np.sum(np.square(X - np.outer(V[:,i],Z[i,:])))/totalVar for i in range(W.shape[1])]\n",
    "    order = np.argsort(explVar)[::-1]\n",
    "    explVar = np.array(explVar)[order[:ncomps]]\n",
    "\n",
    "    W = W[:,order[:ncomps]]\n",
    "    V = V[:,order[:ncomps]]\n",
    "    Z = np.dot(W.T,X)\n",
    "    cumVar = [1 - np.sum(np.square(X - np.dot(V[:,:i+1],Z[:i+1,:])))/totalVar for i in range(W.shape[1])]\n",
    "    return {'obj':dec, 'ev':cumVar, 'trans':Z.T, 'enc':W}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
